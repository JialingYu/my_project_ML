{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd665fb-14db-4066-af77-7e34af338566",
   "metadata": {},
   "source": [
    "# Build and pretrain the GPT2 model\n",
    "\n",
    "This is a practice notebook I wrote after I have read the book 'Build a large labguage model(from scratch)' by Sebastian Reschka. Most of the implementations of codes are from the book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc764e5-0ace-4edf-85ad-8a9748db4be5",
   "metadata": {},
   "source": [
    "## Build the GPT2 model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a056580c-654c-4fab-9294-9f701b0429ab",
   "metadata": {},
   "source": [
    "### Build the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "217cdf42-371e-4c7a-9549-3a3bf9c4c50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.2.2\n",
      "tiktoken version: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# a fast BPE tokenizer for use with openai's model\n",
    "import tiktoken\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91eab6f9-e684-4589-97a7-65aceae1dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the whole GPT2 model\n",
    "class GPT2Model(nn.Module):\n",
    "    #initialize the class with configuration\n",
    "    def __init__(self,conf):\n",
    "        super().__init__()\n",
    "        #define a token embedding which is a look up table where each vocab\n",
    "        #is embedded to size emb_size\n",
    "        self.token_emb=nn.Embedding(conf['vocab_size'],conf['emb_dim'])\n",
    "        #define a position embedding where each position with in context_len\n",
    "        #is embedded to size emb_size\n",
    "        self.pos_emb=nn.Embedding(conf['context_len'],conf['emb_dim'])\n",
    "        #define the dropout layer\n",
    "        self.dropout=nn.Dropout(p=conf['dropout'])\n",
    "        #define transformer blocks\n",
    "        self.trf_blocks=nn.Sequential(*[Trf_layer(conf) for _ in range(conf['n_layers'])])\n",
    "        #define the final layer normalization apply to shape (batch_size,n_tokens,emb_dim)\n",
    "        self.final_laynorm=Layernorm(conf['emb_dim'])\n",
    "        #define the output linear layer to project emb_dim into vocab_size\n",
    "        self.final_proj=nn.Linear(conf['emb_dim'],conf['vocab_size'],bias=False)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        #input x is of shape (batch_size, n_tokens) \n",
    "        batch_size,n_tokens=x.shape\n",
    "        #whose values come from bytepair encoding in GPT2\n",
    "        #embed each token of x into emb_dim dimensional vector\n",
    "        #token_emb_x shape: (batch_size, n_tokens,emb_dim)\n",
    "        token_emb_x=self.token_emb(x) \n",
    "        #position embedding of every position of x along dimension n_tokens\n",
    "        #pos_emb_x shape: (n_tokens,emb_dim)\n",
    "        pos_emb_x=self.pos_emb(torch.arange(n_tokens,device=x.device))\n",
    "        #combine token and position embedding\n",
    "        embbed_x=token_emb_x+pos_emb_x\n",
    "        embbed_x=self.dropout(embbed_x)\n",
    "        #pass through transformer layers\n",
    "        trf_out=self.trf_blocks(embbed_x)\n",
    "        #pass through the final layer normalization\n",
    "        out=self.final_laynorm(trf_out)\n",
    "        #pass throught the output linear layer\n",
    "        logits=self.final_proj(out)\n",
    "        return logits\n",
    "\n",
    "\n",
    "        \n",
    "#define the transformer layer which contains a multihead attention sublayer \n",
    "#and a position-wise feed forward sublayer \n",
    "class Trf_layer(nn.Module):\n",
    "    def __init__(self,conf):\n",
    "        super().__init__()\n",
    "        self.att=Multiheadattention(emb_dim=conf['emb_dim'],\n",
    "                                    d_out=conf['emb_dim'],\n",
    "                                    n_heads=conf['n_heads'],\n",
    "                                    context_len=conf['context_len'],\n",
    "                                    dropout=conf['dropout'],\n",
    "                                   qkv_bias=conf['qkv_bias'])\n",
    "        self.ff=Feedforward(conf['emb_dim'])\n",
    "        self.norm1=Layernorm(conf['emb_dim'])\n",
    "        self.norm2=Layernorm(conf['emb_dim'])\n",
    "        self.dropout=nn.Dropout(conf['dropout'])\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        #define a skip connection for attention sublayer\n",
    "        #define a pre layer normalization before the attention layer and the feed forward layer\n",
    "        #which usually gives better training dynamics than the post layer norm after attention and feed forward\n",
    "        #which used in the original transformer architectures\n",
    "        ori=x\n",
    "        x=self.norm1(x)\n",
    "        x=self.att(x)\n",
    "        x=self.dropout(x)\n",
    "        x=x+ori\n",
    "\n",
    "        #define a skip connection for feed forward sublayer\n",
    "        ori=x\n",
    "        x=self.norm2(x)\n",
    "        x=self.ff(x)\n",
    "        x=self.dropout(x)\n",
    "        x=x+ori\n",
    "        return x\n",
    "        \n",
    "        \n",
    "#define a multihead attention sublayer\n",
    "class Multiheadattention(nn.Module):\n",
    "    def __init__(self,emb_dim,d_out,n_heads,context_len,dropout,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        #emb_dim is the dimension of the token after token embedding\n",
    "        #d_out is the dimension of a token after linear projection\n",
    "        #ensure the last dimension of key,query and value is divisible by the number of heads so that we can split it later\n",
    "        assert d_out%n_heads==0\n",
    "        self.emb_dim=emb_dim\n",
    "        self.d_out=d_out\n",
    "        self.n_heads=n_heads\n",
    "        self.head_dim=d_out//n_heads #use floor division to ensure result is of type int\n",
    "        \n",
    "        self.query_w=nn.Linear(emb_dim,d_out,bias=qkv_bias)\n",
    "        self.key_w=nn.Linear(emb_dim,d_out,bias=qkv_bias)\n",
    "        self.value_w=nn.Linear(emb_dim,d_out,bias=qkv_bias)\n",
    "        #define a mask to be upper triangular positions with 1 and others 0\n",
    "        self.mask_ori=torch.triu(torch.ones(context_len,context_len),diagonal=1)\n",
    "        #register the tensor mask as a persistent buffer of nn.module so that \n",
    "        #it works as the model.parameters() except that it would not be trained by SGD\n",
    "        #i.e, it would be included in model.state_dict() and would be moved together with the model to device\n",
    "        self.register_buffer('mask',self.mask_ori)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.out_proj=nn.Linear(d_out,d_out,bias=qkv_bias)\n",
    "                             \n",
    "    def forward(self,x):#x:(batch_size,n_tokens,emb_dim)\n",
    "        batch_size,n_tokens,emb_dim=x.shape\n",
    "        \n",
    "        #linear projection of x into query, key and value\n",
    "        queries=self.query_w(x) #output:(batch_size,n_tokens,d_out)\n",
    "        keys=self.key_w(x)\n",
    "        values=self.value_w(x)\n",
    "\n",
    "        #split the last dimension d_out into multiheads: n_heads*head_dim=d_out\n",
    "        #(batch_size,n_tokens,d_out)-->(batch_size, n_tokens,self.n_heads,self.head_dim)\n",
    "        queries=queries.view(batch_size, n_tokens,self.n_heads,self.head_dim)\n",
    "        keys=keys.view(batch_size, n_tokens,self.n_heads,self.head_dim)\n",
    "        values=values.view(batch_size, n_tokens,self.n_heads,self.head_dim)\n",
    "\n",
    "        #reshape it to (batch_size,self.n_heads,n_tokens,self.head_dim)\n",
    "        queries=queries.transpose(1,2)\n",
    "        keys=keys.transpose(1,2)\n",
    "        values=values.transpose(1,2)\n",
    "        \n",
    "        #do a scale dot product of queries and keys and use it as the weights of values\n",
    "        att_scores=queries@keys.transpose(2,3)#(batch_size,self.n_heads,n_tokens,n_tokens)\n",
    "        #convert the mask to boolean type and truncate it to n_tokens size\n",
    "        mask=self.mask.bool()[:n_tokens,:n_tokens]\n",
    "        #mask the att_scores where the mask ==True to be negative infinity\n",
    "        att_scores.masked_fill_(mask, -torch.inf)\n",
    "        #apply softmax to the last dimension of the att_scores and convert it to att_weights\n",
    "        att_weights=torch.softmax(att_scores/torch.sqrt(torch.tensor(self.head_dim)), dim=-1)\n",
    "        #apply dropout to attention weights\n",
    "        att_weights=self.dropout(att_weights)\n",
    "\n",
    "        out=att_weights@values #(batch_size,self.n_heads,n_tokens,self.head_dim)\n",
    "        #concate all heads\n",
    "        out=out.transpose(1,2)#(batch_size,n_tokens,self.n_heads,self.head_dim)\n",
    "        #merge the last two dimmension\n",
    "        #call .contiguous() before .view() to make a copy of tensor to ensure that its order\n",
    "        #of elements the same as if it had been created from scratch with the same data\n",
    "        #since we can only apply .view() to contiguous tensor and .view() would not copy the tensor but just change its meta data\n",
    "        #or we can use .reshape() instead which will make a new copy of the tensor if it is not contiguous\n",
    "        out=out.contiguous().view(batch_size,n_tokens,self.d_out)\n",
    "        \n",
    "        out=self.out_proj(out) #optional output_projection\n",
    "        return out\n",
    "\n",
    "#define the layer normalization to normalize the last dimension of the input\n",
    "#i.e., for each token, make its embedded vector to be gaussian unit, i.e., to have mean 0, std 1\n",
    "class Layernorm(nn.Module):\n",
    "    def __init__(self,last_dim):\n",
    "        super().__init__()\n",
    "        #define a small constant to avoid division by zero\n",
    "        self.eps=1e-5\n",
    "        #define shift and scale as parameters to be trained to improve model performance\n",
    "        #since it can happens that the original distribution is better than the normalized distribution\n",
    "        #scale, shift can help us to move between the original distribution and normalized distribution\n",
    "        self.scale=nn.Parameter(torch.ones(last_dim))\n",
    "        self.shift=nn.Parameter(torch.zeros(last_dim))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean=x.mean(dim=-1,keepdim=True)\n",
    "        #we use biased variance(denominator=n) to match the original implementation of GPT2 in tensorflow\n",
    "        var=x.var(dim=-1,keepdim=True, unbiased=False)\n",
    "        x=(x-mean)/torch.sqrt(var+self.eps)\n",
    "        return self.scale*x+self.shift\n",
    "\n",
    "#define Gelu activation layer which is similar with Relu but smooth, and its gradient is \n",
    "#non zero for the negative input\n",
    "#we use a computationally cheaper approximation of Gele\n",
    "class Gelu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "        \n",
    "\n",
    "#define the feed forward layer which is composed of two linear layers and a Gelu activation layer\n",
    "class Feedforward(nn.Module):\n",
    "    def __init__(self,d_out):\n",
    "        #d_out is the dimension of the last dimension of the output of attention sublayer\n",
    "        #in gpt2 it is the same with the token embedding size emb_dim\n",
    "        super().__init__()\n",
    "        #expand the d_out to 4*d_out by the first linear layer to learn more representations\n",
    "        #compress back to original dimension d_out by the second linear layer\n",
    "        self.layers=nn.Sequential(nn.Linear(d_out,4*d_out),\n",
    "                                  Gelu(),\n",
    "                                  nn.Linear(4*d_out,d_out))\n",
    "    def forward(self,x):\n",
    "        return self.layers(x)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff9992b-1709-4e7b-8cac-8e78cf0ef9cd",
   "metadata": {},
   "source": [
    "### Configure a small untrained 124M GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87dcfe8f-d215-4eb3-8084-d0bc2ba29f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_124M={'vocab_size':50257, # Vocabulary size\n",
    "      'emb_dim':768, # Embedding dimension of token and position embedding\n",
    "      'n_layers':12, # Number of transformer layers\n",
    "      'n_heads':12, # Number of attention heads\n",
    "      'dropout':0.1, # Dropout rate\n",
    "      'context_len':1024, # Context length of the context window\n",
    "      'qkv_bias':False # bias of the linear projection of Query-Key-Value\n",
    "     }\n",
    "\n",
    "#instantiate a model with the above configuration\n",
    "gpt2_124m_model=GPT2Model(conf_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f98bfd5-244a-4ca9-a8df-a3269918a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print all the parameters\n",
    "#for name, param in gpt2_124m_model.named_parameters():\n",
    "    #print(name,param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e35a2a8e-41b4-41ca-bdd1-f10f2a4ae513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of parameters of gpt2_124m model is 124402944\n"
     ]
    }
   ],
   "source": [
    "#the total number of parameters of the model\n",
    "total_params=sum(p.numel() for p in gpt2_124m_model.parameters())\n",
    "total_params\n",
    "#since the original GPT2 model reuse the weight of the token embedding as \n",
    "#the weights for final output linear embedding, the actual number of gpt2 model is\n",
    "total_params_gpt2=total_params-sum(p.numel() for p in gpt2_124m_model.final_proj.parameters())\n",
    "print('The total number of parameters of gpt2_124m model is',total_params_gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "733faf9f-a88f-4568-bcff-569e16c9515b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The required memory of the model is 621.80 MB.\n"
     ]
    }
   ],
   "source": [
    "# compute the memory requirement of the model\n",
    "# assume the parameters of the model are of type float32 and are stored in 4 bytes\n",
    "memory_bytes=total_params*4\n",
    "# convert to megabytes\n",
    "memory_mb=memory_bytes/(1024*1024)\n",
    "print(f'The required memory of the model is {memory_mb:.2f} MB.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a9062b-7021-49fb-b696-a79af250177b",
   "metadata": {},
   "source": [
    "### Use the untrained model to generate words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0818756-5449-4172-9c06-d5cb60f5904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_encode(text,tokenizer):\n",
    "    '''a function to encode the text string into token ids and add a batch dimension'''\n",
    "    encoded_tokens=tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
    "    #convert the list to tensor and .unsqueeze(0) add a batch dimension in the first dimension\n",
    "    encoded_tensors=torch.tensor(encoded_tokens).unsqueeze(0)\n",
    "    return encoded_tensors\n",
    "\n",
    "def tokenids_decode(encoded_tokens,tokenizer):\n",
    "    '''a function to decode the encoded tokens to text'''\n",
    "    #encoded_tokens shape: (batch_size=1,n_tokens)\n",
    "    #.squeeze(0) remove the first dimension if it is of size 1\n",
    "    encoded_tokens=encoded_tokens.squeeze(0)\n",
    "    #convert the tensor to list\n",
    "    encoded_tokens=encoded_tokens.tolist()\n",
    "    return tokenizer.decode(encoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f03106d2-0c2b-4a99-8b04-ac340b9e90e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input tokens is of size torch.Size([1, 4]).\n"
     ]
    }
   ],
   "source": [
    "#tokenize a sentence to try the model\n",
    "s='Today is Friday,'\n",
    "\n",
    "#use the gpt2 tokenizer\n",
    "enc=tiktoken.get_encoding('gpt2')\n",
    "\n",
    "encoded_tensors=text_encode(s,enc)\n",
    "print(f'The input tokens is of size {encoded_tensors.shape}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "297d69a9-48a7-40a7-8097-fabd013e85ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to pass text to model and generate outputs\n",
    "def generate_tokens_greedy(encoded_tokens,model,n_generate,model_context_len):\n",
    "    '''a function which input the encoded tokens tensor in shape (batch_size,n_tokens), \n",
    "    pass it to the model n_generate time to generate one token at a time. At each timestep, \n",
    "    use greedy decoding to choose the token with the highest probability as the next token. \n",
    "    Append the token to the input text and pass them to the model again.'''\n",
    "    model.eval()\n",
    "    for _ in range(n_generate):\n",
    "        #take the last part of the tokens if it is out of the range of the context length of the model\n",
    "        encoded_tokens=encoded_tokens[:,-model_context_len:]\n",
    "        #use context manager to close the computation of gradient and save memory\n",
    "        with torch.no_grad():\n",
    "            logits=model(encoded_tokens) #logits shape:(batch_size, n_tokens, 50257)\n",
    "        next_tokens=logits[:,-1,:] # (batch_size,50257) the newly generated token is the last token\n",
    "        probs=torch.softmax(next_tokens,dim=-1) #apply softmax to get the probabilities\n",
    "        next_ids=torch.argmax(probs,dim=-1,keepdim=True) #(batch_size,1)\n",
    "        encoded_tokens=torch.cat((encoded_tokens,next_ids),dim=-1)#(batch_size,n_tokens+1)\n",
    "    return encoded_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29924701-38ce-4a4b-9c7a-acc9d6873986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of output tokens is torch.Size([1, 14]).\n",
      "\n",
      "The output text is \n",
      "Today is Friday,616 Leone ClausHUD Nine roles FPubi anal infringement.\n"
     ]
    }
   ],
   "source": [
    "#get the generated output from the model\n",
    "out_tokens=generate_tokens_greedy(encoded_tensors,gpt2_124m_model,10,conf_124M['context_len'])\n",
    "print(f'The shape of output tokens is {out_tokens.shape}.\\n')\n",
    "#decode the output tokens\n",
    "out_text=tokenids_decode(out_tokens,enc)\n",
    "print(f'The output text is \\n{out_text}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4546002f-206d-451c-8c8f-0e70f733433d",
   "metadata": {},
   "source": [
    "## Pretrain the GPT2 model\n",
    "\n",
    "Since we did not train the model, we can see from above that it generate garbage. Now we will pretrained the gpt2_124m_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee123f74-4081-48fc-bda6-45c4fd75c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the hyperparameters for pretrain\n",
    "n_epochs=10\n",
    "batch_size=2\n",
    "learning_rate=5e-4\n",
    "\n",
    "#define the model configuaration\n",
    "conf_pretrain={'vocab_size':50257, # Vocabulary size\n",
    "      'emb_dim':768, # Embedding dimension of token and position embedding\n",
    "      'n_layers':12, # Number of transformer layers\n",
    "      'n_heads':12, # Number of attention heads\n",
    "      'dropout':0.1, # Dropout rate\n",
    "      'context_len':256, # Context length of the context window, shorted it to facilitate training\n",
    "      'qkv_bias':False # bias of the linear projection of Query-Key-Value\n",
    "     }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03258431-5d45-4a82-a35d-aad99bade707",
   "metadata": {},
   "source": [
    "### Build a dataset and dataloader for pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7210572-e8bb-4834-96c7-53b14a94ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a gpt2 dataset of input data and target data which are \n",
    "#obtained by truncating the corpus text into a list of list of length 'context_len' tokens; \n",
    "#the difference between starting position of the next tokens list and the current tokens list is 'stride'\n",
    "#the target data are the next token of the input data, i.e., the input data shift right by 1\n",
    "\n",
    "class gpt2dataset(Dataset):\n",
    "    def __init__(self,text,tokenizer,context_len,stride):\n",
    "        self.inputs=[]\n",
    "        self.targets=[]\n",
    "        text_ids=tokenizer.encode(text,allowed_special={\"<|endoftext|>\"})\n",
    "        for i in range(0,len(text_ids)-context_len,stride):\n",
    "            input_chunk=text_ids[i:i+context_len]\n",
    "            target_chunk=text_ids[i+1:i+1+context_len]\n",
    "            self.inputs.append(torch.tensor(input_chunk))\n",
    "            self.targets.append(torch.tensor(target_chunk))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.inputs[idx],self.targets[idx]\n",
    "\n",
    "#define a function to create dataset and dataloader to load dataset as batches\n",
    "def create_dataloader(text,context_len,stride,batch_size,\n",
    "                      shuffle,drop_last,num_workers=0):\n",
    "    #create data set\n",
    "    enc=tiktoken.get_encoding('gpt2')\n",
    "    dataset=gpt2dataset(text,enc,context_len,stride)\n",
    "    #the return dataloader is an iterable which has the __iter__() method \n",
    "    #iter(dataloader) will call dataloader.__iter__() and return an iterator object\n",
    "    #iterator object has __next__ method implemented\n",
    "    #next(iterator) will call iterator.__next__ and return the current state\n",
    "    #when iterator is exhausted, stopiteration error will be raise\n",
    "    #for loop is equal to first call iter(iterable) and then call next(iterator) \n",
    "    #until stopiteration error raised\n",
    "    dataloader=DataLoader(dataset,batch_size=batch_size, shuffle=shuffle, \n",
    "                          drop_last=drop_last, num_workers=num_workers)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "029a12c1-d80b-4398-bc2a-b36678e62787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download a short story The Verdict by Edith Wharton if necessary\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "#if no such file, download it\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "#else read it\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "839d2ac3-40ac-448f-a1b8-8bd1f4e6da6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the text is: 20479\n",
      "The number of tokens of the text is: 5145\n"
     ]
    }
   ],
   "source": [
    "text_len=len(text_data)\n",
    "print(f'The length of the text is: {text_len}')\n",
    "tokenizer=tiktoken.get_encoding('gpt2')\n",
    "total_tokens=len(tokenizer.encode(text_data))\n",
    "print(f'The number of tokens of the text is: {total_tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6656776f-baa6-4b7e-9b07-27feae679140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would have been Rome or Florence.)\n",
      "\n",
      "\"The height of his glory\"--that was what the women called it. I can hear Mrs. Gideon Thwing--his last Chicago sitter--deploring his unaccountable abdication. \"Of course it's going to send the value of my picture 'way up; but I don't think of that, Mr. Rickham--the loss to Arrt is all I think of.\" The word, on Mrs. Thwing's lips, multiplied its _rs_ as though they were reflected in an endless vista of mirrors. And it was not only the Mrs. Thwings who mourned. Had not the exquisite Hermia Croft, at the last Grafton Gallery show, stopped me before Gisburn's \"Moon-dancers\" to say, with tears in her eyes: \"We shall not look upon its like again\"?\n",
      "\n",
      "Well!--even through th\n"
     ]
    }
   ],
   "source": [
    "#take a look at the text\n",
    "print(text_data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4c60e42-ed26-4315-b0ba-7822e48e154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training and validation dataloader for gpt2\n",
    "train_ratio=0.8\n",
    "split_idx=int(len(text_data)*train_ratio)\n",
    "train_data=text_data[:split_idx]\n",
    "val_data=text_data[split_idx:]\n",
    "trainloader=create_dataloader(train_data,context_len=conf_pretrain['context_len'],\n",
    "                              stride=conf_pretrain['context_len'],\n",
    "                             batch_size=2,shuffle=True,drop_last=True,num_workers=0)\n",
    "valloader=create_dataloader(val_data,context_len=conf_pretrain['context_len'],\n",
    "                            stride=conf_pretrain['context_len'],\n",
    "                             batch_size=2,shuffle=False,drop_last=False,num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f70a1dfc-4956-44ad-829b-635819ab7429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader:\n",
      "8\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "val loader:\n",
      "2\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "#check that dataloaders are organized correctly\n",
    "print('train_loader:')\n",
    "print(len(trainloader))\n",
    "for x,y in trainloader:\n",
    "    print(x.shape,y.shape)\n",
    "    \n",
    "print('val loader:')\n",
    "print(len(valloader))\n",
    "for x,y in valloader:\n",
    "    print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba39039-2e5d-4093-b60a-00f816e67d88",
   "metadata": {},
   "source": [
    "### Pretrain the gpt2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4ccd092-d5b7-4af3-acb4-8af70916736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the training loop\n",
    "def train_loop(model,dataloader,loss_fn,optimizer,device,print_per=1):\n",
    "    '''define the training loop and return the train loss average over all the batches'''\n",
    "    #set the model to be in training mode to change the behavior of drop out and batch normalization\n",
    "    model.train()\n",
    "    #print(f'dataset is {dataloader.dataset}.')\n",
    "    size=len(dataloader.dataset)\n",
    "    total_loss=0\n",
    "    #iterate over all the batches of the dataloader\n",
    "    for batch_idx, (features,targets) in enumerate(dataloader):\n",
    "        #device setting\n",
    "        features=features.to(device)\n",
    "        targets=targets.to(device)\n",
    "        #clear out the accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "        logits=model(features)\n",
    "        #compute the average loss over all samples of the current batch\n",
    "        loss_batch_average=loss_fn(logits,targets)\n",
    "        #back propagate the loss and compute the gradients for params with requires_grad=True\n",
    "        loss_batch_average.backward()\n",
    "        #update the params with the newly computed gradients according to the optimizer\n",
    "        optimizer.step()\n",
    "        #compute the total loss over all the batches\n",
    "        loss=loss_batch_average.item()\n",
    "        total_loss+=loss\n",
    "        #print the loss every print_per batches\n",
    "        if batch_idx % print_per==0:\n",
    "            #print(batch_idx,batch_size,len(features),size)\n",
    "            current_token = batch_idx * batch_size+len(features)\n",
    "            print(f'Train loss for current batch {loss:>7f}, [{current_token:>5d}/{size:>5d}].')\n",
    "        \n",
    "    total_loss_average=total_loss/len(dataloader)\n",
    "    return total_loss_average\n",
    "    \n",
    "        \n",
    "#define the evaluation loop\n",
    "def eval_loop(model,dataloader,loss_fn,device):\n",
    "    '''define the validation loop and return the validation loss average all the batches'''\n",
    "    #set the model to be in evaluation mode to change the behavior of drop out and batch normalization\n",
    "    model.eval()\n",
    "    n_batches=len(dataloader)\n",
    "    loss_total=0\n",
    "    #tell pytorch not to compute the gradients \n",
    "    with torch.no_grad():\n",
    "        for features, targets in dataloader:\n",
    "            features=features.to(device)\n",
    "            targets=targets.to(device)\n",
    "            logits=model(features)\n",
    "            loss_batch_average=loss_fn(logits,targets)\n",
    "            loss_total+=loss_batch_average.item()\n",
    "    print(f'\\nEvaluation loss for current epoch {loss_total:>7f}.')\n",
    "    model.train()\n",
    "    return loss_total\n",
    "\n",
    "#define the loss function\n",
    "def loss_fn_gpt2(logits_b,targets_b):\n",
    "    '''define the loss function, reshape logits and targets to use the cross_entropy loss'''\n",
    "    #reshape the logits and targets to use torch.nn.functional.corss_entropyloss\n",
    "    #logits_b shape: (batch_size,n_tokens,vocab_size)\n",
    "    #targets_b shape:(batch_size,n_tokens)\n",
    "    #since F.cross_entropy expect input,target to be of shape (batch_size,n_classes) and (batch_size)\n",
    "    #we thus need to flatten the logits_b and targets_b\n",
    "    loss=F.cross_entropy(logits_b.flatten(0,1),targets_b.flatten())\n",
    "    return loss\n",
    "    \n",
    "#define a function to generate text after start_text after epoch during training\n",
    "def generate_and_print_sample(model,start_text,tokenizer,device,n_generate):\n",
    "    '''tokenize start_text using tokenizer, move it to device,\n",
    "    and pass it to model to generate n_generate new words'''\n",
    "    model.eval()\n",
    "    #tokenizer the start_text into tokens and move it to device\n",
    "    encoded_tokens=text_encode(start_text,tokenizer).to(device)\n",
    "    #encoded_tokens shape (batch_size=1, n_tokens)\n",
    "    #get the context window size of the model\n",
    "    model_context_len=model.pos_emb.weight.shape[0]\n",
    "    #pass the token_ids to model to generate output \n",
    "    with torch.no_grad():\n",
    "        out_tokens=generate_tokens_greedy(encoded_tokens,model,n_generate,model_context_len)\n",
    "    #out_tokens shape (batch_size=1, n_tokens)\n",
    "    #decode the output\n",
    "    out_text=tokenids_decode(out_tokens,tokenizer)\n",
    "    print(f'\\nThe output text of the current epoch is:\\n{out_text}.')\n",
    "    #convert back the model to training mode\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5c137d0-88c1-454f-8ecf-9b1bbf5dfc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------------\n",
      "Train loss for current batch 10.996353, [    2/   16].\n",
      "Train loss for current batch 9.844820, [    4/   16].\n",
      "Train loss for current batch 9.412277, [    6/   16].\n",
      "Train loss for current batch 9.156552, [    8/   16].\n",
      "Train loss for current batch 8.828124, [   10/   16].\n",
      "Train loss for current batch 8.587851, [   12/   16].\n",
      "Train loss for current batch 8.090243, [   14/   16].\n",
      "Train loss for current batch 7.998214, [   16/   16].\n",
      "\n",
      "Evaluation loss for current epoch 15.060107.\n",
      "\n",
      "The output text of the current epoch is:\n",
      "Today is Friday, the the the the the the the the the the the the, the the the the the the the.\n",
      "Epoch 2\n",
      "--------------------------------------\n",
      "Train loss for current batch 7.039148, [    2/   16].\n",
      "Train loss for current batch 7.109453, [    4/   16].\n",
      "Train loss for current batch 6.568961, [    6/   16].\n",
      "Train loss for current batch 6.472637, [    8/   16].\n",
      "Train loss for current batch 6.335046, [   10/   16].\n",
      "Train loss for current batch 6.117278, [   12/   16].\n",
      "Train loss for current batch 6.385320, [   14/   16].\n",
      "Train loss for current batch 6.064250, [   16/   16].\n",
      "\n",
      "Evaluation loss for current epoch 13.745126.\n",
      "\n",
      "The output text of the current epoch is:\n",
      "Today is Friday, I the.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "Epoch 3\n",
      "--------------------------------------\n",
      "Train loss for current batch 5.836478, [    2/   16].\n",
      "Train loss for current batch 5.636061, [    4/   16].\n",
      "Train loss for current batch 5.600895, [    6/   16].\n",
      "Train loss for current batch 5.568412, [    8/   16].\n",
      "Train loss for current batch 15.836017, [   10/   16].\n",
      "Train loss for current batch 5.763179, [   12/   16].\n",
      "Train loss for current batch 5.776493, [   14/   16].\n",
      "Train loss for current batch 5.919666, [   16/   16].\n",
      "\n",
      "Evaluation loss for current epoch 13.694748.\n",
      "\n",
      "The output text of the current epoch is:\n",
      "Today is Friday, I had been.\n",
      "\", and, I was, and, and, the, the,.\n",
      "Epoch 4\n",
      "--------------------------------------\n",
      "Train loss for current batch 5.210557, [    2/   16].\n",
      "Train loss for current batch 4.856631, [    4/   16].\n",
      "Train loss for current batch 5.714223, [    6/   16].\n",
      "Train loss for current batch 4.851836, [    8/   16].\n",
      "Train loss for current batch 5.521767, [   10/   16].\n",
      "Train loss for current batch 5.851601, [   12/   16].\n",
      "Train loss for current batch 4.461226, [   14/   16].\n",
      "Train loss for current batch 6.027532, [   16/   16].\n",
      "\n",
      "Evaluation loss for current epoch 13.685567.\n",
      "\n",
      "The output text of the current epoch is:\n",
      "Today is Friday, the the was.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "Epoch 5\n",
      "--------------------------------------\n",
      "Train loss for current batch 4.628126, [    2/   16].\n",
      "Train loss for current batch 4.878241, [    4/   16].\n",
      "Train loss for current batch 4.949173, [    6/   16].\n",
      "Train loss for current batch 3.928399, [    8/   16].\n",
      "Train loss for current batch 4.922497, [   10/   16].\n",
      "Train loss for current batch 3.861535, [   12/   16].\n",
      "Train loss for current batch 4.704148, [   14/   16].\n",
      "Train loss for current batch 4.106320, [   16/   16].\n",
      "\n",
      "Evaluation loss for current epoch 13.590928.\n",
      "\n",
      "The output text of the current epoch is:\n",
      "Today is Friday, as a him, as a a of his pictures--as, as of a little, as,.\n",
      "Epoch 6\n",
      "--------------------------------------\n",
      "Train loss for current batch 2.485908, [    2/   16].\n",
      "Train loss for current batch 3.404278, [    4/   16].\n",
      "Train loss for current batch 4.530814, [    6/   16].\n",
      "Train loss for current batch 4.020582, [    8/   16].\n",
      "Train loss for current batch 3.977019, [   10/   16].\n",
      "Train loss for current batch 3.744079, [   12/   16].\n",
      "Train loss for current batch 3.481510, [   14/   16].\n",
      "Train loss for current batch 3.728441, [   16/   16].\n",
      "\n",
      "Evaluation loss for current epoch 13.563248.\n",
      "\n",
      "The output text of the current epoch is:\n",
      "Today is Friday, in the picture, and he was, and he was, and he was a little of the picture.\n",
      "Epoch 7\n",
      "--------------------------------------\n",
      "Train loss for current batch 3.351538, [    2/   16].\n",
      "Train loss for current batch 2.538552, [    4/   16].\n",
      "Train loss for current batch 2.236274, [    6/   16].\n",
      "Train loss for current batch 3.035255, [    8/   16].\n",
      "Train loss for current batch 2.395290, [   10/   16].\n",
      "Train loss for current batch 2.565023, [   12/   16].\n",
      "Train loss for current batch 3.020493, [   14/   16].\n",
      "Train loss for current batch 2.789972, [   16/   16].\n",
      "\n",
      "Evaluation loss for current epoch 13.578175.\n",
      "\n",
      "The output text of the current epoch is:\n",
      "Today is Friday, in the picture.\n",
      "\n",
      "\"I didn't--and by his pictures--and that he never.\n",
      "Epoch 8\n",
      "--------------------------------------\n",
      "Train loss for current batch 1.827959, [    2/   16].\n",
      "Train loss for current batch 1.789512, [    4/   16].\n",
      "Train loss for current batch 2.273540, [    6/   16].\n",
      "Train loss for current batch 2.424395, [    8/   16].\n",
      "Train loss for current batch 2.384923, [   10/   16].\n",
      "Train loss for current batch 1.129226, [   12/   16].\n",
      "Train loss for current batch 2.062400, [   14/   16].\n",
      "Train loss for current batch 2.216449, [   16/   16].\n",
      "\n",
      "Evaluation loss for current epoch 13.799405.\n",
      "\n",
      "The output text of the current epoch is:\n",
      "Today is Friday, in the inevitable garlanded.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"Oh, I.\n",
      "Epoch 9\n",
      "--------------------------------------\n",
      "Train loss for current batch 0.844270, [    2/   16].\n",
      "Train loss for current batch 1.476775, [    4/   16].\n",
      "Train loss for current batch 1.331790, [    6/   16].\n",
      "Train loss for current batch 1.612738, [    8/   16].\n",
      "Train loss for current batch 1.274790, [   10/   16].\n",
      "Train loss for current batch 1.095027, [   12/   16].\n",
      "Train loss for current batch 1.353993, [   14/   16].\n",
      "Train loss for current batch 1.421662, [   16/   16].\n",
      "\n",
      "Evaluation loss for current epoch 13.903196.\n",
      "\n",
      "The output text of the current epoch is:\n",
      "Today is Friday, in the inevitable garlanded frame. Gisburn--as such--had not existed till nearly.\n",
      "Epoch 10\n",
      "--------------------------------------\n",
      "Train loss for current batch 0.665009, [    2/   16].\n",
      "Train loss for current batch 1.034501, [    4/   16].\n",
      "Train loss for current batch 0.806524, [    6/   16].\n",
      "Train loss for current batch 0.732794, [    8/   16].\n",
      "Train loss for current batch 0.680698, [   10/   16].\n",
      "Train loss for current batch 0.844652, [   12/   16].\n",
      "Train loss for current batch 0.932491, [   14/   16].\n",
      "Train loss for current batch 0.792908, [   16/   16].\n",
      "\n",
      "Evaluation loss for current epoch 14.196764.\n",
      "\n",
      "The output text of the current epoch is:\n",
      "Today is Friday, in the inevitable garlanded frame. Gisburn--as, in a self-confident.\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "#instatiate the model\n",
    "model=GPT2Model(conf_pretrain)\n",
    "\n",
    "#define an optimizer for model training\n",
    "optimizer=torch.optim.AdamW(model.parameters(),lr=learning_rate,weight_decay=0.1)\n",
    "\n",
    "#move the model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "#define a start text to use model to generate words to to visualize the effect of training\n",
    "start_text='Today is Friday,'\n",
    "#use the gpt2 tokenizer\n",
    "tokenizer=tiktoken.get_encoding('gpt2')\n",
    "#generate 20 words for visualization\n",
    "n_generate=20\n",
    "\n",
    "#save the training loss and validation loss for each epoch for later visulization\n",
    "train_losses_epochs, val_losses_epochs=[],[]\n",
    "for e in range(n_epochs):\n",
    "    print(f'Epoch {e+1}\\n--------------------------------------')\n",
    "    train_loss=train_loop(model,trainloader,loss_fn_gpt2,optimizer,device,print_per=1)\n",
    "    train_losses_epochs.append(train_loss)\n",
    "    val_loss=eval_loop(model,valloader,loss_fn_gpt2,device)\n",
    "    val_losses_epochs.append(val_loss)\n",
    "    generate_and_print_sample(model,start_text,tokenizer,device,n_generate)\n",
    "print('Finished!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94b6b993-00dc-4d0c-b5c3-b9e87db79227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define a function to plot the training losses and validation losses\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(epochs,train_losses,val_losses):\n",
    "    fig,ax=plt.subplots(figsize=(5,3))\n",
    "    ax.plot(epochs,train_losses,label='Training loss')\n",
    "    ax.plot(epochs,val_losses,linestyle='-.',label='Validation loss')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "epochs=torch.arange(1,n_epochs+1)\n",
    "plot_losses(epochs,train_losses_epochs, val_losses_epochs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9148a72-36de-433e-b585-7f8c44c365d7",
   "metadata": {},
   "source": [
    "We can see from the graph that the validation loss does not decrease after the second epoch while the training loss is still decreasing. In addition, the validation loss is much larger than training loss, which signifies that the model is overfitting to the training data but does not generalize well to the validation data. This phenomenon is expected since compared to the number of parameters of our model, our training data set has only around 4000 tokens, whihc is very small. Thus our model is in fact memorizing the training text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db547423-b62f-4f21-971a-3da9a3da042e",
   "metadata": {},
   "source": [
    "### Use top-k sampling and temperature scaling to adjust text generation\n",
    "\n",
    "In the previous 'generate_tokens_greedy()' function, the way we generate text after we get the logits from the model is first apply the softmax function to turn the logits into probability and then use argmax function to choose the token with the highest probability as the next token. This process is deterministic in a way that if we pass the input text to the model again, the generated output text will always be the same. If we would like to add more diversity to our generated text we can modify the way we deal with the output logits.\n",
    "\n",
    "One way is to use top-k sampling and temperature scaling. From the output logits of shape (batch_size, n_tokens, vocab_size) we take the last token batch which is of shape (batch_size, vocab_size). And then instead of applying the softmax function to the logits of all the vocabularies, we only retain the vocabularies with largest k probabilities and set the logits of other vacaularies to negative infinity. which means we would not sample from those vocabularies. Then we apply temperature scaling to\n",
    "\n",
    "And then we apply the softmax function which converts the top-k vocabularies to its corresponding probabilities and other to probability 0, which means we would not sample from those vocabularies. Then we apply temperature scaling to the logits, i.e., we devide each logits by given temperature. after that we apply the softmax function to convert the logits to probailities. If the temperature >1, the distribution of the probabilities would be more uniform and if temperature <1, the distribution of the probability would be sharper. Finally we can apply the multinomal function to sample token according to the probability distribution instead of applying the argmax function to only sample the token with largest probability, which gives more diversity to the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cee03b8-a2f0-4801-8a15-1eff0d23ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def top_k_and_temperature(encoded_tokens,model,n_generate,model_context_len,top_k=None,\n",
    "                          temperature=0):\n",
    "    '''use the model for inference, input start_text to the model and get the output logits,\n",
    "    apply top_k sampling to only choose the top_k highest tokens as condidates for next token,\n",
    "    apply softmax to get the probabilities for the k candidates,\n",
    "    scale the logits by temperature and sample from the scaled'''\n",
    "    model.eval()\n",
    "    for _ in range(n_generate):\n",
    "        #only take the last part of encoded_ids within context len\n",
    "        encoded_tokens=encoded_tokens[:,-model_context_len:]\n",
    "        #print(encoded_tokens)\n",
    "        with torch.no_grad():\n",
    "            logits=model(encoded_tokens)\n",
    "            #logits shape: (batch_size, n_tokens,vocab_size)\n",
    "        #get the next tokens\n",
    "        #next_tokens shape:(batch_size,vocab_size)\n",
    "        next_tokens=logits[:,-1,:]\n",
    "        if top_k is not None:\n",
    "            values,indices=torch.topk(next_tokens,top_k)\n",
    "            #values shape: (batch_size,top_k)\n",
    "            #print(values.shape,indices.shape)\n",
    "            #take the smallest value from the top k\n",
    "            values_min=values[:,-1]\n",
    "            #print('values_min:', values_min)\n",
    "            #values_min shape: (batch_size,)\n",
    "            #print(values_min.shape)\n",
    "            #if the condition is satisfied, take values from input\n",
    "            #otherwise, take input from other\n",
    "            #mask the non top k values into -inf\n",
    "            next_tokens=torch.where(\n",
    "                condition=next_tokens<values_min,\n",
    "                input=torch.tensor(float('-inf')).to(logits.device),\n",
    "                other=next_tokens\n",
    "            )\n",
    "            #print('next_token shape:',next_tokens)\n",
    "            #print('next_tokens:',(next_tokens!= torch.tensor(float('-inf'))).sum(dim=-1))\n",
    "        #if we use temperature scaling, we divide the next_tokens by the temperature\n",
    "        #and apply softamex to get the probability and use multinomial to sample from \n",
    "        #the probability, otherwise we use argmax to get the topen with max prob directly\n",
    "        if temperature>0:\n",
    "            next_tokens=next_tokens/temperature\n",
    "            probs=torch.softmax(next_tokens,dim=-1)\n",
    "            #for each row of probs, sample one sample from its probability distribution\n",
    "            next_ids=torch.multinomial(probs,1)\n",
    "            #print('next_ids',next_ids)\n",
    "        else:\n",
    "            next_ids=torch.argmax(next_tokens,dim=-1,keepdim=True)\n",
    "        encoded_tokens=torch.cat((encoded_tokens,next_ids),dim=-1)\n",
    "    return encoded_tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15eac6d2-dfcd-44e9-90b6-4c6abe7b7440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text is: Today is Friday, in ext of to have been too? You \"Yes were like one of such an so dis.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(222)\n",
    "tokenizer=tiktoken.get_encoding('gpt2')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_generate=20\n",
    "start_text='Today is Friday'\n",
    "top_k=30\n",
    "temperature=1.5\n",
    "out_token_ids=top_k_and_temperature(text_encode(start_text,tokenizer),\n",
    "                      model,n_generate,conf_pretrain['context_len'],\n",
    "                      top_k,temperature)\n",
    "print(f'Output text is: {tokenids_decode(out_token_ids,tokenizer)}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57733c1f-ab4e-4711-bc64-4e048d2870fa",
   "metadata": {},
   "source": [
    "## Save the pretrained model's parameters and the optimizer's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dd33c8b-b2a2-4d17-b443-9bc671af8fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model parameters dictionary\n",
    "torch.save(model.state_dict(),'model.pth')\n",
    "\n",
    "#if we need to continue to train the model, we can also save the optimzer's parameters\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict':optimizer.state_dict()},\n",
    "           'model_and_optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "390a3cca-c239-48c5-9e6b-2191e1f49b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#when we need to use the saved the model, we can first \n",
    "#instantiate the model using the same configurations\n",
    "#and then load back the model parameters\n",
    "\n",
    "#load back the parameters dictionary checkpoint\n",
    "checkpoint=torch.load('model_and_optimizer.pth',map_location=device)\n",
    "model_reloaded=GPT2Model(conf_pretrain)\n",
    "model_reloaded.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "#if we need to continue training the model, we can load  back the optimizer's parameters\n",
    "#instatiate the optimizer using the same configuration\n",
    "optimizer=torch.optim.AdamW(model_reloaded.parameters(),lr=5e-4,weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cffc3925-1ce1-47ac-8e14-f43a888baf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jialingyu/Documents/github_local/my_project_ML/build, pretrain and fine-tuned a large language model/Build and pretrain a gpt2 model\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b293e4-b28a-400b-921d-9b479dd3bc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
